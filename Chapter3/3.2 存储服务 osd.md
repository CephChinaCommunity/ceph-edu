OSD用于实现数据的存储和维护。根据定义，OSD可以被抽象为系统和守护进程（OSD Daemon）两个部分。

OSD的系统部分本质上就是一台安装了操作系统和文件系统的计算机，实际应用中通常将多个OSD集中部署在一台更大规模的服务器上。在选择系统配置时，应当能够保证每个OSD占用一定的计算能力、一定数量的内存和一块硬盘（在通常情况下一个OSD对应一块硬盘）。同时，应当保证该服务器具备足够的网络带宽。

每个OSD拥有一个自己的OSD Daemon。这个Daemon负责完成OSD的所有逻辑功能，包括与Monitor和其他OSD（事实上是其他OSD的Daemon）通信，以维护及更新系统状态，与其他OSD共同完成数据的存储，处理数据复制、恢复、重新平衡，并通过检查其他 Ceph OSD 守护进程的心跳向 Ceph 监视器和管理器提供一些监控信息，等等。

### 3.2.1 数据存储

Ceph 存储集群从 Ceph 客户端接收数据（无论是通过 Ceph 块设备、Ceph 对象存储、Ceph 文件系统还是您使用 librados 创建的自定义实现）并将数据存储为对象。 如图3-2所示，每个对象对应于文件系统中的一个文件，该文件存储在 OSD 的存储设备上，由 Ceph OSD 守护进程处理存储磁盘上的读/写操作。

<center> <img src="https://docs.ceph.com/en/nautilus/_images/fa62eb11bb3e4b873e7fd16e73cedc1904c4e948827199b88b31feb1e7cddf2b.png"> <br> <div style="color:orange; border-bottom: 1px solid #d9d9d9; display: inline-block; color: #999; padding: 2px;">图3-2 Ceph数据存储</div> </center>

Ceph OSD 守护进程将所有数据作为对象存储在平面命名空间中（例如，没有目录层次结构）。 对象具有标识符、二进制数据和由一组名称/值对组成的元数据。 语义完全取决于 Ceph 客户端。 例如，CephFS 使用元数据来存储文件属性，例如文件所有者、创建日期、上次修改日期等。

<center> <img src="https://docs.ceph.com/en/nautilus/_images/4ed8cdf2e8556555185907b4725c51c04704111b65598e30d43b6be77eb3948d.png"> <br> <div style="color:orange; border-bottom: 1px solid #d9d9d9; display: inline-block; color: #999; padding: 2px;">图3-3 Ceph数据存储</div> </center>

### 3.2.2 状态检测

当集群规模达到PB级别以后，集群中一般包含大量的 OSD，此时 OSD 故障会成为常态。为了保障存储服务可靠性，及时且完善的故障检测变的尤为重要。

为了区分故障类型，例如是临时性故障（例如停机维护）还是永久性故障（例如硬盘损坏），方便选择合理的数据恢复策略，Ceph 为每个 OSD 赋予了 4 种基本状态，如表3-1所示。

<center><div style="color:orange; border-bottom: 1px solid #d9d9d9; display: inline-block; color: #999; padding: 2px;">表3-1 OSD 的 4 种基本状态</div> </center>

| 状态 | 含义                                            |
| ---- | ----------------------------------------------- |
| Up   | 正常状态，OSD 启动                              |
| Down | 异常状态，OSD 停止，不会触发 PG 迁移            |
| In   | 正常状态，OSD 处于 Crush Root中                 |
| Out  | 异常状态，OSD 处于 Crush Root外，会触发 PG 迁移 | 

根据以上 4 种状态，我们在集群中实际观测到的，是他们的组合，在同一个 OSD 上，Up 和 Down或者 In 和 Out 不会同时出现，所以我们可以得出实际能够观测到的 4 种组合状态，如表3-2所示。

<center><div style="color:orange; border-bottom: 1px solid #d9d9d9; display: inline-block; color: #999; padding: 2px;">表3-2 OSD 的 4 种组合状态</div> </center>

| 组合状态   | 含义                                                                                     |
| ---------- | ---------------------------------------------------------------------------------------- |
| Up & In    | OSD Daemon工作的正常状态，有PG分配到OSD上                                                |
| Up & Out   | OSD Daemon与Monitor通信正常，但是没有PG分配到该OSD上。这种状态一般是OSD Daemon刚刚启动时 |
| Down & In  | OSD Daemon不能与Monitor或其他OSD进行正常通信，这可能是因为网络中断或Daemon进程意外退出   |
| Down & Out | OSD无法恢复，Monitor决定将OSD上的PG进行重新分配。之所以会出现该状态，是考虑OSD可能会在短时间内恢复，尽量减少数据的再分配                                                                                         |

由于心跳（Heartbeat）机制简单有效，所以Ceph采用这种方式检测节点故障及网络故障，但是会增加监测维度。

- OSD 之间的心跳检测

OSD 如何选择有效的伙伴 OSD，最简单的思路莫过于让每个 OSD 以广播的形式直接与所有其他 OSD 进行心跳检测。但是这样存在很大的弊端，首先会对集群性能产生影响，其次，如果一个集群存在大量 OSD，采取广播的方式很容易引起心跳风暴。所以 Ceph 选择 PeerOSD 发送心跳包。PeerOSD 是指该 OSD 上所有 PG 的副本所在的 OSD。同时由于 Ceph 提供公共网络（PublicNetwork）（OSD 与客户端通信）和集群网络（Cluster Network）（OSD之间的通信），所以 PeerOSD 之间的心跳包也分为前端（公共网络）和后端（集群网络），这样可最大限度地监测 OSD 及公共网络和集群网络的状态，及时上报 Monitor。同时考虑到网络的抖动问题，可以设置 Monitor 在决定 OSD 下线之前需要收到多少次的报告。
- OSD 与 Monitor 之间的心跳检测

每个 OSD 需要周期性（默认为 300s）地向 Monitor 发送 Beacon 消息进行保活，如果 Monitor 在一段时间内（默认为 900s）没有收到某个 OSD 的任何 Beacon 消息，则将该 OSD 标记为 Down。Monitor 如果检测到某个 OSD 处于 Down 状态超过一定时间（默认为 600s），会将其进一步的设置为 Out 状态。

### 3.2.3 IO 流程

客户端将对象写入主 OSD 中指定的归置组。 然后，主 OSD 和它自己的 CRUSH 映射副本识别二级和三级 OSD 以进行复制，并将对象复制到二级和三级 OSD 中的适当归置组（与附加副本一样多的 OSD），并响应 客户端一旦确认对象存储成功。

<center> <img src="https://docs.ceph.com/en/nautilus/_images/6324fc870f294e5e407722de1ff965eb6b8a40a55c1b512174d7f3ecbd7b4b56.png"> <br> <div style="color:orange; border-bottom: 1px solid #d9d9d9; display: inline-block; color: #999; padding: 2px;">图3-4 Ceph IO 流程</div> </center>
